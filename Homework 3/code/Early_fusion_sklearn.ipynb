{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/efs/11775-hw2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data_path = 'Passt/'\n",
    "video_data_path = '../11775-hw2-handout/data/cnn2d_1d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/labels/train_val.csv')\n",
    "val_df = pd.read_csv('data/labels/val.csv')\n",
    "test_df = pd.read_csv('data/labels/test_for_students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_list = os.listdir(audio_data_path)\n",
    "video_file_list = os.listdir(video_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'batch_size': 64,\n",
    "          'epochs': 10,\n",
    "          'learning_rate': 0.001,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(label_df):\n",
    "    feat_all = []\n",
    "    label_all = []\n",
    "    \n",
    "    for ix, row in tqdm(label_df.iloc[:].iterrows()):\n",
    "        Id = label_df.iloc[ix].Id\n",
    "        category = train_df.iloc[ix].Category\n",
    "        if Id+'.csv' in audio_file_list:\n",
    "            audio_feat = pd.read_csv(os.path.join(audio_data_path, Id+'.csv')).values\n",
    "            audio_feat = audio_feat.reshape(-1, 1)\n",
    "        else:\n",
    "            print(Id)\n",
    "            continue\n",
    "        if Id+'.pkl' in video_file_list:\n",
    "            with open(os.path.join(video_data_path, Id+'.pkl'), 'rb') as f:\n",
    "                video_feat = pickle.load(f)\n",
    "                video_feat = video_feat[1].numpy().reshape(-1, 1)\n",
    "        else:\n",
    "            print(Id)\n",
    "            continue\n",
    "        \n",
    "\n",
    "        feature = np.concatenate([audio_feat, video_feat]).squeeze()\n",
    "        feat_all.append(feature)\n",
    "        label_all.append(category)\n",
    "\n",
    "    feat_all = torch.FloatTensor(np.stack(feat_all))\n",
    "    label_all = torch.FloatTensor(np.stack(label_all))\n",
    "\n",
    "    length = len(feat_all)\n",
    "    \n",
    "    return feat_all, label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1146it [00:07, 160.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTQ5ODI3NjU5MTQ3OTQ4NTAwOQ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3159it [00:19, 160.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTkxNzA4MjE4OTM1ODg4NTYxOA==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7062it [00:44, 159.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTgxOTM5Mzg2MTMwNzM4NjQzNzg=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7500it [00:46, 159.90it/s]\n",
      "310it [00:01, 278.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTQ5ODI3NjU5MTQ3OTQ4NTAwOQ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1760it [00:06, 273.92it/s]\n",
      "749it [00:04, 153.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = data_loading(train_df.iloc[:])\n",
    "val_x, val_y = data_loading(val_df.iloc[:])\n",
    "test_x, test_y = data_loading(test_df.iloc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.61950404\n",
      "Iteration 2, loss = 0.62966126\n",
      "Iteration 3, loss = 0.31781233\n",
      "Iteration 4, loss = 0.21771714\n",
      "Iteration 5, loss = 0.16455354\n",
      "Iteration 6, loss = 0.13246934\n",
      "Iteration 7, loss = 0.11031081\n",
      "Iteration 8, loss = 0.08786745\n",
      "Iteration 9, loss = 0.07938841\n",
      "Iteration 10, loss = 0.07484779\n",
      "Iteration 11, loss = 0.05839098\n",
      "Iteration 12, loss = 0.05760411\n",
      "Iteration 13, loss = 0.04779342\n",
      "Iteration 14, loss = 0.04260763\n",
      "Iteration 15, loss = 0.03978156\n",
      "Iteration 16, loss = 0.03617854\n",
      "Iteration 17, loss = 0.03231652\n",
      "Iteration 18, loss = 0.03446668\n",
      "Iteration 19, loss = 0.03061536\n",
      "Iteration 20, loss = 0.02400317\n",
      "Iteration 21, loss = 0.01942564\n",
      "Iteration 22, loss = 0.01966005\n",
      "Iteration 23, loss = 0.01748253\n",
      "Iteration 24, loss = 0.01772135\n",
      "Iteration 25, loss = 0.01771043\n",
      "Iteration 26, loss = 0.01453295\n",
      "Iteration 27, loss = 0.01432472\n",
      "Iteration 28, loss = 0.01221833\n",
      "Iteration 29, loss = 0.01160442\n",
      "Iteration 30, loss = 0.01140017\n",
      "Iteration 31, loss = 0.01156949\n",
      "Iteration 32, loss = 0.01078757\n",
      "Iteration 33, loss = 0.01011717\n",
      "Iteration 34, loss = 0.00876794\n",
      "Iteration 35, loss = 0.00875441\n",
      "Iteration 36, loss = 0.00809354\n",
      "Iteration 37, loss = 0.00799784\n",
      "Iteration 38, loss = 0.00763150\n",
      "Iteration 39, loss = 0.00709919\n",
      "Iteration 40, loss = 0.00713102\n",
      "Iteration 41, loss = 0.00682139\n",
      "Iteration 42, loss = 0.00691049\n",
      "Iteration 43, loss = 0.00692169\n",
      "Iteration 44, loss = 0.00768315\n",
      "Iteration 45, loss = 0.00612937\n",
      "Iteration 46, loss = 0.00579556\n",
      "Iteration 47, loss = 0.00591712\n",
      "Iteration 48, loss = 0.00592944\n",
      "Iteration 49, loss = 0.00554064\n",
      "Iteration 50, loss = 0.00562629\n",
      "Iteration 51, loss = 0.00560040\n",
      "Iteration 52, loss = 0.00525016\n",
      "Iteration 53, loss = 0.00511579\n",
      "Iteration 54, loss = 0.00501242\n",
      "Iteration 55, loss = 0.00509339\n",
      "Iteration 56, loss = 0.00495846\n",
      "Iteration 57, loss = 0.00475571\n",
      "Iteration 58, loss = 0.00483374\n",
      "Iteration 59, loss = 0.00467258\n",
      "Iteration 60, loss = 0.00467688\n",
      "Iteration 61, loss = 0.00461640\n",
      "Iteration 62, loss = 0.00447919\n",
      "Iteration 63, loss = 0.00441478\n",
      "Iteration 64, loss = 0.00439239\n",
      "Iteration 65, loss = 0.00428324\n",
      "Iteration 66, loss = 0.00422930\n",
      "Iteration 67, loss = 0.00417455\n",
      "Iteration 68, loss = 0.00417480\n",
      "Iteration 69, loss = 0.00407634\n",
      "Iteration 70, loss = 0.00406804\n",
      "Iteration 71, loss = 0.00403039\n",
      "Iteration 72, loss = 0.00398045\n",
      "Iteration 73, loss = 0.00396435\n",
      "Iteration 74, loss = 0.00392037\n",
      "Iteration 75, loss = 0.00387164\n",
      "Iteration 76, loss = 0.00384520\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.001, hidden_layer_sizes=1024, validation_fraction=0.2,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, hidden_layer_sizes=1024, validation_fraction=0.2,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=1024, validation_fraction=0.2,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(1024), activation=\"relu\",solver=\"adam\",alpha=1e-3, verbose=True, validation_fraction=0.2)\n",
    "# clf.fit(X_train, y_train)\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06765207504263786"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes = clf.predict(val_x)\n",
    "accuracy_score(val_y, torch.Tensor(pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = clf.predict(test_x)\n",
    "# accuracy_score(val_y, pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4., 12., 14., 12.,  6.,  1.,  8.,  3.,  3.,  4.,  1.,  4.,  8.,\n",
       "        4.,  9., 12.,  5.,  2.,  2.,  6.,  8.,  5., 12.,  1.,  3.,  0.,\n",
       "        0., 13., 13.,  1.,  1., 11.,  3.,  0.,  3.,  0.,  6.,  2.,  9.,\n",
       "       14., 13., 14.,  4.,  9., 14., 14.,  5., 14., 10., 11., 10.,  2.,\n",
       "        5., 12., 10.,  4.,  7., 12., 14., 10.,  0.,  7., 10.,  2.,  2.,\n",
       "        7., 14.,  9.,  3., 10., 11., 14.,  1., 10., 14., 13., 13.,  7.,\n",
       "        4., 11., 13.,  5.,  3.,  0.,  3.,  6.,  4.,  7., 11.,  9.,  8.,\n",
       "        4., 11.,  0.,  8.,  9.,  3., 12.,  4.,  7.,  7.,  4.,  1., 10.,\n",
       "        3., 13.,  1.,  4.,  8.,  1.,  3.,  1., 10.,  9.,  0.,  3.,  9.,\n",
       "        2.,  6.,  2., 11., 11.,  9.,  7.,  5.,  2.,  8.,  3.,  7.,  1.,\n",
       "       10.,  4.,  5.,  0.,  0.,  2.,  6.,  9.,  0.,  1.,  1.,  4.,  6.,\n",
       "       10.,  5.,  8.,  9., 11.,  3.,  6.,  1.,  0., 12., 11.,  8., 12.,\n",
       "        8., 13.,  6.,  8., 14.,  9., 11.,  3.,  4.,  1.,  7., 12., 10.,\n",
       "        3.,  3., 12., 12.,  6.,  5.,  3.,  0.,  4., 10., 11.,  7., 13.,\n",
       "        5.,  6., 10., 14.,  6.,  2.,  4., 13., 13.,  4., 13., 13.,  9.,\n",
       "       11.,  9.,  1., 11., 10., 13.,  3., 11., 12.,  1., 10.,  2.,  3.,\n",
       "        5.,  8.,  5.,  5.,  5.,  9.,  1., 13.,  7.,  0., 11.,  5., 10.,\n",
       "       13.,  8.,  8.,  9.,  6.,  6., 11.,  9., 13.,  5., 14., 13.,  8.,\n",
       "        6., 11., 11.,  8.,  5.,  4., 10.,  8.,  1.,  9.,  1.,  1.,  4.,\n",
       "        5., 10.,  0.,  3., 12.,  2., 14.,  6.,  5.,  8.,  1., 10., 12.,\n",
       "        7.,  0.,  7., 14., 12.,  8.,  5.,  2.,  8., 10., 14.,  2., 14.,\n",
       "        5.,  1., 14.,  0., 11.,  6., 11.,  2.,  6.,  0.,  6., 10.,  4.,\n",
       "        1., 13., 11.,  9.,  6.,  0.,  1., 14.,  7.,  0.,  3.,  5.,  2.,\n",
       "        5., 13., 13., 11.,  9.,  4., 10.,  9.,  9.,  2., 12., 10.,  8.,\n",
       "        2., 13., 10., 14., 10.,  6.,  2.,  4.,  0.,  7.,  9.,  2.,  6.,\n",
       "        3.,  0., 12.,  5.,  9., 11., 12.,  9.,  5.,  2.,  2.,  0.,  6.,\n",
       "       13.,  7.,  3., 11.,  0., 13.,  8.,  3.,  9.,  5.,  9., 11., 12.,\n",
       "        7.,  8., 13.,  2., 12.,  4.,  7., 12.,  0., 11.,  3.,  1., 11.,\n",
       "        9.,  8.,  7.,  6.,  5., 12.,  2., 14.,  7.,  8.,  4.,  2.,  5.,\n",
       "        7.,  8.,  4.,  4.,  7.,  2., 11.,  4.,  8.,  1.,  4.,  6.,  9.,\n",
       "        4., 11.,  8.,  3.,  2.,  8.,  8.,  4., 11.,  9.,  7.,  1., 13.,\n",
       "        9.,  1.,  5., 12.,  2., 10., 14.,  6.,  7.,  4., 13., 13.,  0.,\n",
       "        1.,  4.,  3., 14.,  7.,  0.,  8.,  6.,  7., 12.,  2.,  5.,  8.,\n",
       "        6., 10.,  6., 10.,  7.,  4.,  9.,  5.,  4., 12.,  4.,  0.,  4.,\n",
       "        7.,  7., 12.,  4.,  2.,  4.,  6.,  5.,  7.,  3.,  9.,  8., 11.,\n",
       "        1.,  2.,  0., 13.,  0.,  1., 12.,  1., 13.,  8.,  1., 12., 12.,\n",
       "        0., 11.,  9., 10.,  4.,  4.,  7., 10., 11., 11., 13., 10.,  5.,\n",
       "        3.,  2.,  6., 13.,  7., 12.,  5.,  6., 13., 13., 11.,  0.,  7.,\n",
       "        3.,  9., 10.,  6.,  6., 12.,  0., 13.,  6., 10., 14.,  3.,  3.,\n",
       "        3.,  8., 14., 14., 14.,  3., 11.,  5.,  7., 14., 10., 14., 13.,\n",
       "       12., 11., 12., 12.,  7.,  6., 11., 10., 13.,  5.,  7., 12.,  7.,\n",
       "        0., 13.,  4., 12.,  2.,  0.,  1.,  6.,  4.,  7.,  6.,  0., 14.,\n",
       "        1.,  1.,  1., 10., 12., 14., 13.,  3.,  6.,  7., 14.,  6., 12.,\n",
       "       10., 14.,  1., 12.,  6.,  9.,  5.,  0.,  1.,  8.,  6.,  1., 13.,\n",
       "       14.,  7., 10., 11.,  5.,  0.,  8., 13.,  9., 11.,  5.,  9.,  1.,\n",
       "        0., 11.,  3.,  3.,  9.,  0., 13., 11., 11.,  1., 14.,  9., 11.,\n",
       "        0.,  8., 14.,  4.,  2., 12.,  5.,  8.,  5.,  3.,  1., 12.,  6.,\n",
       "        7.,  0., 14.,  4.,  7.,  3.,  6.,  6.,  5., 14.,  3., 11.,  0.,\n",
       "       10.,  3.,  8.,  9.,  1.,  3., 12.,  7.,  5.,  4.,  3., 14., 10.,\n",
       "        1.,  0., 13.,  0.,  9.,  8.,  6.,  7., 14., 10.,  8., 12.,  5.,\n",
       "        9., 13.,  8., 12., 12.,  4., 10.,  3.,  8.,  5., 13., 10., 14.,\n",
       "        0.,  4.,  4.,  5., 11.,  0.,  8.,  2., 14., 10.,  2.,  5.,  2.,\n",
       "        2.,  8., 12.,  5.,  5., 10.,  8.,  2., 12.,  7.,  6., 12., 14.,\n",
       "        8., 12., 11.,  9., 14.,  6.,  1.,  6.,  5.,  7., 12., 10.,  3.,\n",
       "        1., 12., 11.,  0.,  4.,  2.,  1.,  1.,  7.,  0.,  5.,  3.,  3.,\n",
       "       10.,  7.,  8., 12., 13.,  3., 14.,  5.,  6., 13., 10.,  3.,  0.,\n",
       "       13., 10.,  6.,  7.,  9.,  2.,  9., 12.,  9.,  9.,  7.,  5.,  6.,\n",
       "        5., 13.,  7., 14.,  9.,  2., 11.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/early_sklearn_passt.csv', \"w\") as f:\n",
    "    f.writelines(\"Id,Category\\n\")\n",
    "    for i, pred_class in enumerate(pred_classes):\n",
    "      f.writelines(\"%s,%d\\n\" % (test_df.Id[i], pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: kaggle: command not found\n"
     ]
    }
   ],
   "source": [
    "# !kaggle competitions submit -c 11775-fall2022-hw3 -f output/sklearn_1.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('11775-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04b48ee4f9f19dc028124efcfb56b4058c9376c2249723c47d2f8e367dde6361"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
